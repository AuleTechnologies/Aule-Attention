#version 450

// FlashAttention-2 Forward Pass - fp32 version
// Implements tiled attention with online softmax for O(N) memory complexity

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

// Storage buffers
layout(std430, set = 0, binding = 0) readonly buffer QBuffer {
    float data[];
} Q;

layout(std430, set = 0, binding = 1) readonly buffer KBuffer {
    float data[];
} K;

layout(std430, set = 0, binding = 2) readonly buffer VBuffer {
    float data[];
} V;

layout(std430, set = 0, binding = 3) writeonly buffer OutputBuffer {
    float data[];
} O;

layout(std430, set = 0, binding = 4) readonly buffer RotaryCosBuffer {
    float data[];
} RotCos;

layout(std430, set = 0, binding = 5) readonly buffer RotarySinBuffer {
    float data[];
} RotSin;

// Push constants for dimensions
layout(push_constant) uniform PushConstants {
    uint batch_size;    // B
    uint num_heads;     // H
    uint seq_len;       // N
    uint head_dim;      // D (must be <= 64)
    float scale;        // 1/sqrt(D)
    uint causal;        // 1 for causal masking
    uint has_rope;      // 1 to apply RoPE
    uint num_kv_heads;  // New: Number of K/V heads
    uint key_seq_len;   // New: Sequence length for K/V
    int window_size;    // Sliding window size (-1 for full attention)
} params;

// Shared memory for tiles
const uint BLOCK_SIZE = 16;

shared float s_Q[BLOCK_SIZE][64];       // Q tile: Br x D
shared float s_K[BLOCK_SIZE][64];       // K tile: Bc x D
shared float s_V[BLOCK_SIZE][64];       // V tile: Bc x D
shared float s_S[BLOCK_SIZE][BLOCK_SIZE]; // Attention scores: Br x Bc

void main() {
    uint local_row = gl_LocalInvocationID.y;  // Row within block
    uint local_col = gl_LocalInvocationID.x;  // Col within block

    // Global position
    uint batch_head_idx = gl_WorkGroupID.z;
    uint batch_idx = batch_head_idx / params.num_heads;
    uint head_idx = batch_head_idx % params.num_heads;
    
    // GQA Logic
    uint ratio = params.num_heads / params.num_kv_heads;
    uint kv_head_idx = head_idx / ratio;
    uint kv_batch_head_idx = batch_idx * params.num_kv_heads + kv_head_idx;
    
    // Base offsets
    uint qs_off = batch_head_idx * params.seq_len * params.head_dim;
    uint ks_off = kv_batch_head_idx * params.key_seq_len * params.head_dim;
    uint vs_off = kv_batch_head_idx * params.key_seq_len * params.head_dim;
    uint block_row = gl_WorkGroupID.y;

    uint global_row = block_row * BLOCK_SIZE + local_row;

    // Check availability
    bool is_active = (batch_idx < params.batch_size) && (global_row < params.seq_len);

    uint base_offset = qs_off; // Use calculated qs_off as base for Q

    // Initialize output accumulator
    float row_max = -1e30;
    float row_sum = 0.0;
    float output_acc[64];
    uint actual_head_dim = min(params.head_dim, 64u);

    for (uint d = 0; d < actual_head_dim; d++) {
        output_acc[d] = 0.0;
    }

    // Load Q tile
    for (uint d = local_col; d < actual_head_dim; d += BLOCK_SIZE) {
        float q_val = 0.0;
        if (is_active) {
            q_val = Q.data[base_offset + global_row * params.head_dim + d];
            
            // RoPE
            if (params.has_rope != 0u) {
                uint rot_idx = global_row * (params.head_dim / 2) + (d / 2);
                float c = RotCos.data[rot_idx];
                float s = RotSin.data[rot_idx];
                float pair_val;
                if ((d % 2) == 0) {
                    pair_val = Q.data[base_offset + global_row * params.head_dim + (d + 1)];
                    q_val = q_val * c - pair_val * s;
                } else {
                    pair_val = Q.data[base_offset + global_row * params.head_dim + (d - 1)];
                    q_val = pair_val * s + q_val * c;
                }
            }
        }
        s_Q[local_row][d] = q_val;
    }
    barrier();

    // Iterate over K/V blocks
    uint num_kv_blocks = (params.key_seq_len + BLOCK_SIZE - 1) / BLOCK_SIZE;

    for (uint kv_block = 0; kv_block < num_kv_blocks; kv_block++) {
        uint kv_start = kv_block * BLOCK_SIZE;
        uint kv_row = kv_start + local_row;
        bool kv_valid = kv_row < params.key_seq_len;

        // Load K tile
        for (uint d = local_col; d < actual_head_dim; d += BLOCK_SIZE) {
            float k_val = 0.0;
            if (kv_valid && batch_idx < params.batch_size) {
                uint k_idx = ks_off + kv_row * params.head_dim + d;
                k_val = K.data[k_idx];
                
                // RoPE K
                if (params.has_rope != 0u) {
                    uint rot_idx = kv_row * (params.head_dim / 2) + (d / 2);
                    float c = RotCos.data[rot_idx];
                    float s = RotSin.data[rot_idx];
                    bool is_even = (d % 2 == 0);
                    uint pair_idx = ks_off + kv_row * params.head_dim + (is_even ? d+1 : d-1);
                    float k_pair = K.data[pair_idx];
                    if (is_even) k_val = k_val * c - k_pair * s;
                    else k_val = k_pair * s + k_val * c;
                }
            }
            s_K[local_row][d] = k_val;
        }

        // Load V tile
        for (uint d = local_col; d < actual_head_dim; d += BLOCK_SIZE) {
            float v_val = 0.0;
            if (kv_valid && batch_idx < params.batch_size) {
                v_val = V.data[vs_off + kv_row * params.head_dim + d];
            }
            s_V[local_row][d] = v_val;
        }
        barrier();

        // Compute scores
        float score = 0.0;
        for (uint d = 0; d < actual_head_dim; d++) {
            score += s_Q[local_row][d] * s_K[local_col][d];
        }
        score *= params.scale;

        // Masks
        uint global_col = kv_start + local_col;
        bool is_masked = !is_active || global_col >= params.key_seq_len;

        // Causal masking: can't attend to future positions
        if (params.causal != 0u && global_col > global_row) is_masked = true;

        // Sliding window masking: can only attend within window_size positions
        // window_size == -1 means full attention (no window)
        if (params.window_size > 0) {
            // For causal: only look back window_size positions
            // For bidirectional: look window_size/2 in each direction
            if (params.causal != 0u) {
                // Causal sliding window: [global_row - window_size + 1, global_row]
                if (int(global_row) - int(global_col) >= params.window_size) is_masked = true;
            } else {
                // Bidirectional sliding window: centered around current position
                int half_window = params.window_size / 2;
                int distance = abs(int(global_row) - int(global_col));
                if (distance > half_window) is_masked = true;
            }
        }

        if (is_masked) score = -1e30;

        s_S[local_row][local_col] = score;
        barrier();

        // Online Softmax
        if (is_active) {
            float block_max = -1e30;
            for (uint c = 0; c < BLOCK_SIZE; c++) block_max = max(block_max, s_S[local_row][c]);

            float new_max = max(row_max, block_max);
            float old_scale_factor = exp(row_max - new_max);
            
            row_sum = row_sum * old_scale_factor;
            for (uint d = 0; d < actual_head_dim; d++) output_acc[d] *= old_scale_factor;

            float block_sum = 0.0;
            for (uint c = 0; c < BLOCK_SIZE; c++) {
                float p = exp(s_S[local_row][c] - new_max);
                block_sum += p;
                for (uint d = 0; d < actual_head_dim; d++) {
                    output_acc[d] += p * s_V[c][d];
                }
            }
            row_sum += block_sum;
            row_max = new_max;
        }
        barrier();
    }

    // Output
    if (is_active && batch_idx < params.batch_size) {
        float inv_sum = 1.0 / row_sum;
        for (uint d = local_col; d < actual_head_dim; d += BLOCK_SIZE) {
            float val = output_acc[d] * inv_sum;
            O.data[qs_off + global_row * params.head_dim + d] = val;
        }
    }
}
